[device]
input_samplerate = 48000
output_samplerate = 48000
input_device = ""
output_device = ""

[asr]
whisper_model = "medium" # recommended: large-v3-turbo for accuracy, medium for lower load
device = "cuda"
compute_type = "int8"
task = "translate"
language = "ko"
beam_size = 3
temperature = 0.0
vad = true

[vad]
frame_ms = 30
aggressiveness = 3
min_speech_sec = 0.30
silence_pad_ms = 400
max_segment_ms = 9000
chunk_enable = false
# ---- Forced Segmentation (when VAD misses speech) ----
[vad.force]
enable = false
rms_speech_threshold_dbfs = -33.0  # >= this is considered speech-like
min_forced_segment_ms = 2000      # minimum duration to cut on loud->quiet
sustained_loud_ms = 7000          # force if loud this long with no VAD end
max_buffer_ms = 20000             # cap buffer


[tts]
engine = "kokoro"
voice = "en-US-AriaNeural"
piper_model = ""
pace = 1.0
volume_db = 13.4

[kokoro]
model = "hexgrad/Kokoro-82M"
speaker = "af_bella"
backend = "auto"  # auto | pytorch | onnx
device = "auto"
use_half = true
onnx_model = ""
onnx_providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
execution_provider = ""
passthrough_input_device = ""  # Optional: mirror Kokoro audio to another device (e.g., virtual mic)
short_threshold_ms = 320.0
min_batch_ms = 500.0
max_batch_ms = 1000.0
medium_min_ms = 750.0
medium_max_ms = 1500.0
crossfade_ms = 120.0
tail_flush_ms = 320.0
short_idle_flush_ms = 500.0
warmup_runs = 2

[app]
preset = "accuracy"

[translator]
use_llm = true
llm_backend = "lmstudio"  # ollama | lmstudio
timeout_sec = 8.0
temperature = 0.2

[translator.ollama]
base_url = "http://localhost:11434"
model = ""

[translator.lmstudio]
base_url = "http://localhost:1234/v1"
model = "qwen/qwen3-4b-2507"

[stream]
mode = "chunk"
normalize_dbfs = -2.5

[voice_changer]
enabled = false
base_url = "http://localhost:18000"
endpoint = "/api/voice-changer/convert_chunk"
input_sample_rate = 0
output_sample_rate = 0
timeout_sec = 5.0
save_original_path = "cache/tts_original.wav"
save_converted_path = "cache/tts_converted.wav"
fallback_endpoint = "/api/voice-changer/convert_chunk_bulk"
fallback_output_device = ""
stream_mode = false
stream_chunk_ms = 1000

[logging]
level = "INFO"

