[device]
input_samplerate = 48000
output_samplerate = 48000
input_device = ""
output_device = ""

[asr]
whisper_model = "large-v3-turbo"
device = "cpu"
compute_type = "int8"
task = "translate"
language = "ko"
beam_size = 1
temperature = 0.0
vad = true

[vad]
frame_ms =30
aggressiveness = 3
min_speech_sec = 0.30
max_utterance_sec = 9
silence_end_ms = 400

[tts]
engine = "kokoro"
voice = "en-US-AriaNeural"
piper_model = ""
pace = 1.0
volume_db = 0.0

[kokoro]
model = "hexgrad/Kokoro-82M"
speaker = ""
backend = "auto"  # auto | pytorch | onnx
device = "auto"
use_half = true
onnx_model = ""
onnx_providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
execution_provider = ""
short_threshold_ms = 500.0
min_batch_ms = 900.0
max_batch_ms = 1200.0
medium_min_ms = 800.0
medium_max_ms = 1500.0
crossfade_ms = 120.0
tail_flush_ms = 350.0
short_idle_flush_ms = 650.0
warmup_runs = 2

[app]
preset = "latency"

[stream]
mode = "chunk"
normalize_dbfs = -16

[voice_changer]
enabled = true
base_url = "http://localhost:18000"
endpoint = "/api/voice-changer/convert_chunk"
input_sample_rate = 0
output_sample_rate = 0
timeout_sec = 5.0
save_original_path = "cache/tts_original.wav"
save_converted_path = "cache/tts_converted.wav"
fallback_endpoint = "/api/voice-changer/convert_chunk_bulk"
fallback_output_device = ""
stream_mode = false
stream_chunk_ms = 1000

[logging]
level = "INFO"
